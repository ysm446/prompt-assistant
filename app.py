"""
app.py
SD Ã— Qwen3-VL ç”»åƒç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ - Gradio ã‚¢ãƒ—ãƒªæœ¬ä½“
"""

import os
import re
import shutil
import threading
import time
import json

import gradio as gr
from PIL import Image
from PIL.PngImagePlugin import PngInfo

import a1111_client
import comfyui_client
import qwen_client
import settings_manager
from prompt_parser import parse_prompt_update, read_a1111_metadata, read_comfyui_metadata

DEFAULT_SAMPLER = "Euler a"


# ---------------------------------------------------------------------------
# ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
# ---------------------------------------------------------------------------

def on_load_model(model_label: str) -> str:
    model_id = qwen_client.MODEL_PRESETS.get(model_label, model_label)
    try:
        return qwen_client.load_model(model_id)
    except RuntimeError as e:
        return str(e)


def on_image_drop(
    image: Image.Image,
    state: dict,
    sampler_choices: list[str],
) -> tuple:
    """
    ç”»åƒãŒãƒ‰ãƒ­ãƒƒãƒ—ï¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã¨ãã®å‡¦ç†ã€‚
    A1111 ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«åæ˜ ã™ã‚‹ã€‚
    """
    if image is None:
        return (
            state,
            gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(),
            "ç”»åƒãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰ã€‚",
        )

    state["current_image"] = image
    meta = read_a1111_metadata(image) or read_comfyui_metadata(image)

    if meta is None:
        msg = "ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Qwen3-VL ã«å†…å®¹ã‚’åˆ†æã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
        return (
            state,
            gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(),
            msg,
        )

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿å–ã‚ŒãŸå ´åˆã¯å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°
    positive = meta.get("positive", "")
    negative = meta.get("negative", "")
    state["positive_prompt"] = positive
    state["negative_prompt"] = negative

    steps_update = gr.update(value=meta["steps"]) if "steps" in meta else gr.update()
    cfg_update = gr.update(value=meta["cfg_scale"]) if "cfg_scale" in meta else gr.update()

    sampler_val = meta.get("sampler")
    sampler_update = (
        gr.update(value=sampler_val)
        if sampler_val and sampler_val in sampler_choices
        else gr.update()
    )

    width_update = gr.update(value=meta["width"]) if "width" in meta else gr.update()
    height_update = gr.update(value=meta["height"]) if "height" in meta else gr.update()
    seed_update = gr.update(value=meta["seed"]) if "seed" in meta else gr.update()
    comfyui_seed_update = gr.update(value=meta["seed"]) if "seed" in meta else gr.update()

    source = "A1111" if image.info.get("parameters") else "ComfyUI"
    msg = f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åæ˜ ã—ã¾ã—ãŸã€‚ï¼ˆ{source}ï¼‰"
    return (
        state,
        gr.update(value=positive),
        gr.update(value=negative),
        steps_update,
        cfg_update,
        sampler_update,
        width_update,
        height_update,
        seed_update,
        comfyui_seed_update,
        msg,
    )


def on_clear(state: dict) -> tuple:
    """ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚"""
    state["conversation_history"] = []
    return state, []


def on_set_seed_random() -> int:
    return -1


def on_set_seed_from_current_image(state: dict) -> tuple:
    image = state.get("current_image")
    if image is None:
        return gr.update(), "ç¾åœ¨ã®ç”»åƒãŒãªã„ãŸã‚ Seed ã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚"

    meta = read_a1111_metadata(image) or read_comfyui_metadata(image)
    if meta is None or "seed" not in meta:
        return gr.update(), "ç¾åœ¨ã®ç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã« Seed ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    seed = int(meta["seed"])
    return gr.update(value=seed), f"ç¾åœ¨ã®ç”»åƒã® Seed ã‚’åæ˜ ã—ã¾ã—ãŸ: {seed}"


def _get_next_image_sequence(save_dir: str) -> int:
    pattern = re.compile(r"^(\d{5})-(-?\d+)\.png$")
    max_seq = 0
    try:
        for name in os.listdir(save_dir):
            match = pattern.match(name)
            if not match:
                continue
            seq = int(match.group(1))
            if seq > max_seq:
                max_seq = seq
    except Exception:
        return 1
    return max_seq + 1


def _get_next_video_sequence(save_dir: str) -> int:
    pattern = re.compile(r"^(\d{5})-(-?\d+)\.(mp4|webm|avi|mov)$", re.IGNORECASE)
    max_seq = 0
    try:
        for name in os.listdir(save_dir):
            match = pattern.match(name)
            if not match:
                continue
            seq = int(match.group(1))
            if seq > max_seq:
                max_seq = seq
    except Exception:
        return 1
    return max_seq + 1


def _build_pnginfo_from_image(image: Image.Image) -> PngInfo | None:
    info = getattr(image, "info", {}) or {}
    pnginfo = PngInfo()
    added = False
    for key, value in info.items():
        if value is None:
            continue
        if isinstance(value, str):
            pnginfo.add_text(str(key), value)
            added = True
            continue
        if isinstance(value, (dict, list)):
            try:
                pnginfo.add_text(str(key), json.dumps(value, ensure_ascii=False))
                added = True
            except Exception:
                continue
    return pnginfo if added else None


def on_send(
    user_input: str,
    state: dict,
    chatbot: list,
    model_label: str,
    positive: str,
    negative: str,
):
    """
    ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ï¼šQwen3-VL ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å•ã„åˆã‚ã›ã‚‹ã€‚
    ãƒ¢ãƒ‡ãƒ«æœªãƒ­ãƒ¼ãƒ‰ã®å ´åˆã¯è‡ªå‹•çš„ã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    """
    if not user_input.strip():
        yield state, chatbot, gr.update(), gr.update(), "", gr.update()
        return

    # UIä¸Šã®ç¾åœ¨å€¤ã§ state ã‚’æ›´æ–°
    state["positive_prompt"] = positive
    state["negative_prompt"] = negative

    auto_load_status = None
    if not qwen_client.is_loaded():
        # ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã‚ã‚‹ã“ã¨ã‚’è¡¨ç¤º
        yield (
            state,
            chatbot + [
                {"role": "user", "content": user_input},
                {"role": "assistant", "content": "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."},
            ],
            gr.update(), gr.update(), "", gr.update(value="ãƒ­ãƒ¼ãƒ‰ä¸­..."),
        )
        model_id = qwen_client.MODEL_PRESETS.get(model_label, model_label)
        try:
            auto_load_status = qwen_client.load_model(model_id)
        except RuntimeError as e:
            auto_load_status = str(e)
        if not qwen_client.is_loaded():
            yield (
                state,
                chatbot + [
                    {"role": "user", "content": user_input},
                    {"role": "assistant", "content": f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {auto_load_status}"},
                ],
                gr.update(), gr.update(), "", gr.update(value=auto_load_status),
            )
            return

    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ
    partial_response = ""
    streaming_chatbot = chatbot + [
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": ""},
    ]

    try:
        for token in qwen_client.query_stream(
            conversation_history=state["conversation_history"],
            user_input=user_input,
            current_image=state.get("current_image"),
            positive_prompt=positive,
            negative_prompt=negative,
        ):
            partial_response += token
            streaming_chatbot[-1]["content"] = partial_response
            yield state, streaming_chatbot, gr.update(), gr.update(), "", gr.update()
    except Exception as e:
        yield (
            state,
            chatbot + [
                {"role": "user", "content": user_input},
                {"role": "assistant", "content": f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"},
            ],
            gr.update(), gr.update(), "", gr.update(),
        )
        return

    positive_new, negative_new, display_text = parse_prompt_update(partial_response)

    # ä¼šè©±å±¥æ­´ã‚’æ›´æ–°ï¼ˆç”»åƒã¯ current_image ã¨ã—ã¦åˆ¥ç®¡ç†ï¼‰
    state["conversation_history"].append({"role": "user", "content": [{"type": "text", "text": user_input}]})
    state["conversation_history"].append({"role": "assistant", "content": partial_response})

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ›´æ–°ãŒã‚ã‚Œã° state ã«åæ˜ 
    positive_update = gr.update()
    negative_update = gr.update()
    if positive_new is not None:
        state["positive_prompt"] = positive_new
        positive_update = gr.update(value=positive_new)
    if negative_new is not None:
        state["negative_prompt"] = negative_new
        negative_update = gr.update(value=negative_new)

    # æœ€çµ‚ yield: [PROMPT_UPDATE] ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤ã„ãŸè¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã«å·®ã—æ›¿ãˆ
    final_chatbot = chatbot + [
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": display_text},
    ]
    status_update = gr.update(value=auto_load_status) if auto_load_status else gr.update()
    yield state, final_chatbot, positive_update, negative_update, "", status_update


def on_free_qwen() -> str:
    return qwen_client.unload_model()


def on_free_forge() -> str:
    return a1111_client.free_vram()


def on_free_comfyui() -> str:
    return comfyui_client.free_vram()


def on_generate(
    state: dict,
    positive: str,
    negative: str,
    steps: int,
    cfg: float,
    sampler: str,
    width: int,
    height: int,
    seed: int,
    backend: str,
    comfyui_workflow: str,
    comfyui_width: int,
    comfyui_height: int,
    comfyui_seed: int,
    count: int,
    save_generated_image: bool,
    image_save_path: str,
):
    """
    ã€Œç”»åƒç”Ÿæˆã€ãƒœã‚¿ãƒ³ï¼šé¸æŠä¸­ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ã‚‹ã€‚
    count=1 ã§1æšã€count>1 ã§æŒ‡å®šæšæ•°ã€count=0 ã§åœæ­¢ãƒœã‚¿ãƒ³ã¾ã§ç„¡é™ç”Ÿæˆã€‚
    """
    state["positive_prompt"] = positive
    state["negative_prompt"] = negative
    count = max(1, int(count) if count is not None else 1)
    save_enabled = bool(save_generated_image)
    save_dir = (image_save_path or "").strip() or "./outputs/images"
    _comfyui_seed_base = int(comfyui_seed) if comfyui_seed is not None else -1
    _forge_seed_base = int(seed) if seed is not None else -1
    for i in range(1, count + 1):
        _comfyui_seed_i = (_comfyui_seed_base + (i - 1)) if _comfyui_seed_base != -1 else -1
        _forge_seed_i = (_forge_seed_base + (i - 1)) if _forge_seed_base != -1 else -1
        try:
            _start = time.time()
            if backend == "ComfyUI":
                workflow_path = comfyui_client.IMAGE_WORKFLOW_PRESETS.get(comfyui_workflow, comfyui_workflow)
                image = comfyui_client.generate_image(
                    workflow_path=workflow_path,
                    positive=positive,
                    negative=negative,
                    seed=_comfyui_seed_i,
                    width=int(comfyui_width) if comfyui_width else None,
                    height=int(comfyui_height) if comfyui_height else None,
                )
            else:
                image = a1111_client.generate_image(
                    positive=positive,
                    negative=negative,
                    steps=steps,
                    cfg=cfg,
                    sampler=sampler,
                    width=width,
                    height=height,
                    seed=_forge_seed_i,
                )
            elapsed = time.time() - _start
            state["current_image"] = image
            if backend == "ComfyUI":
                state["current_image_stem"] = comfyui_client.get_last_output_filename()
            else:
                state["current_image_stem"] = time.strftime("forge_%Y%m%d_%H%M%S")
            save_status = ""
            if save_enabled:
                try:
                    os.makedirs(save_dir, exist_ok=True)
                    meta = read_a1111_metadata(image) or read_comfyui_metadata(image) or {}
                    seed_value = meta.get("seed")
                    if seed_value is None:
                        seed_value = _comfyui_seed_i if backend == "ComfyUI" else _forge_seed_i
                    seed_value = int(seed_value)
                    next_seq = _get_next_image_sequence(save_dir)
                    filename = f"{next_seq:05d}-{seed_value}.png"
                    save_path = os.path.join(save_dir, filename)
                    pnginfo = _build_pnginfo_from_image(image)
                    if pnginfo is not None:
                        image.save(save_path, pnginfo=pnginfo)
                    else:
                        image.save(save_path)
                    save_status = f" / ä¿å­˜: {save_path}"
                except Exception as save_error:
                    save_status = f" / ä¿å­˜å¤±æ•—: {save_error}"
            suffix = f"ï¼ˆ{i}/{count}æšï¼‰" if count > 1 else ""
            yield state, image, f"ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚{suffix}ï¼ˆ{elapsed:.1f}ç§’ï¼‰{save_status}"
        except Exception as e:
            yield state, None, f"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
            break


def on_generate_video_prompt(state: dict, positive: str, extra_instruction: str, sections: list):
    """
    ã€Œå‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã€ãƒœã‚¿ãƒ³ï¼šç”»åƒãƒ»ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»è¿½åŠ æŒ‡ç¤ºã‹ã‚‰å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆç”Ÿæˆã™ã‚‹ã€‚
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¯ä½¿ã‚ãšã€video_prompt ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã™ã‚‹ã€‚
    """
    if not sections:
        yield "ç”Ÿæˆã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚"
        return

    if not extra_instruction.strip() and not positive.strip():
        yield "è¿½åŠ æŒ‡ç¤ºã¾ãŸã¯ Positive Prompt ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        return

    if not qwen_client.is_loaded():
        yield "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."
        model_id = qwen_client.MODEL_PRESETS.get(
            state.get("model", list(qwen_client.MODEL_PRESETS.keys())[0]),
            list(qwen_client.MODEL_PRESETS.keys())[0],
        )
        try:
            qwen_client.load_model(model_id)
        except RuntimeError as e:
            yield f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
            return

    accumulated = ""
    try:
        for token in qwen_client.generate_video_prompt_stream(
            image=state.get("current_image"),
            positive_prompt=positive,
            extra_instruction=extra_instruction,
            sections=sections,
        ):
            accumulated += token
            yield accumulated
    except Exception as e:
        yield f"å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"


# å‹•ç”»ç”Ÿæˆã®ä¸–ä»£ã‚«ã‚¦ãƒ³ã‚¿ï¼šæ–°ã—ã„ç”Ÿæˆã¾ãŸã¯åœæ­¢ã®ãŸã³ã«ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã—ã€
# å¤ã„ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµæœãŒå¾Œã‹ã‚‰è¡¨ç¤ºã•ã‚Œã‚‹ã®ã‚’é˜²ãã€‚
_video_gen_id = 0


def on_stop_video():
    """åœæ­¢ãƒœã‚¿ãƒ³ï¼šComfyUI ã®ç”Ÿæˆã‚’ä¸­æ–­ã—ã€ä¸–ä»£ã‚«ã‚¦ãƒ³ã‚¿ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã—ã¦çµæœã‚’ç ´æ£„ã™ã‚‹ã€‚"""
    global _video_gen_id
    _video_gen_id += 1
    comfyui_client.interrupt()
    return "å‹•ç”»ç”Ÿæˆã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ"


def on_generate_video(
    state: dict,
    video_prompt_text: str,
    workflow_name: str,
    seed,
    width,
    height,
    save_generated_video: bool,
    video_save_path: str,
):
    """
    ã€Œå‹•ç”»ç”Ÿæˆã€ãƒœã‚¿ãƒ³ï¼šComfyUI ã«ç”»åƒ + å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ã£ã¦å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    global _video_gen_id
    _video_gen_id += 1
    my_id = _video_gen_id

    image = state.get("current_image")
    if image is None:
        yield state, gr.update(), "ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ç”»åƒã‚¨ãƒªã‚¢ã«ç”»åƒã‚’ã‚»ãƒƒãƒˆã—ã¦ãã ã•ã„ã€‚"
        return
    actual_seed = int(seed) if seed is not None else -1
    actual_width  = int(width)  if width  else None
    actual_height = int(height) if height else None
    save_enabled = bool(save_generated_video)
    save_dir = (video_save_path or "").strip() or "./outputs/videos"

    result_box: list = []
    error_box: list = []

    def _run():
        # å®Ÿè¡Œé–‹å§‹å‰ã«ã™ã§ã«æ–°ã—ã„ä¸–ä»£ãŒå§‹ã¾ã£ã¦ã„ãŸã‚‰å³çµ‚äº†
        if my_id != _video_gen_id:
            return
        try:
            workflow_path = comfyui_client.VIDEO_WORKFLOW_PRESETS.get(workflow_name, workflow_name)
            result_box.append(comfyui_client.generate_image(
                workflow_path=workflow_path,
                positive=video_prompt_text,
                negative="",
                seed=actual_seed,
                width=actual_width,
                height=actual_height,
                input_image=image,
            ))
        except Exception as e:
            error_box.append(e)

    t = threading.Thread(target=_run, daemon=True)
    t.start()
    start = time.time()

    while t.is_alive():
        # Gradio ãŒã“ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ãŸå ´åˆã€æ¬¡ã® yield ã§åœæ­¢ã™ã‚‹
        if my_id != _video_gen_id:
            return
        elapsed = time.time() - start
        yield state, gr.update(), f"å‹•ç”»ç”Ÿæˆä¸­... {elapsed:.0f}ç§’"
        time.sleep(1)

    # ã‚¹ãƒ¬ãƒƒãƒ‰å®Œäº†å¾Œã€ã™ã§ã«æ–°ã—ã„ä¸–ä»£ãŒå§‹ã¾ã£ã¦ã„ãŸã‚‰çµæœã‚’æ¨ã¦ã‚‹
    if my_id != _video_gen_id:
        return

    elapsed = time.time() - start
    if error_box:
        yield state, gr.update(), f"å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {error_box[0]}"
    elif result_box:
        result = result_box[0]
        if isinstance(result, str):
            save_status = ""
            if save_enabled:
                try:
                    os.makedirs(save_dir, exist_ok=True)
                    next_seq = _get_next_video_sequence(save_dir)
                    ext = os.path.splitext(result)[1].lower() or ".mp4"
                    if ext not in {".mp4", ".webm", ".avi", ".mov"}:
                        ext = ".mp4"
                    used_seed = comfyui_client.get_last_actual_seed()
                    if used_seed is None or int(used_seed) < 0:
                        used_seed = int(actual_seed)
                    filename = f"{next_seq:05d}-{int(used_seed)}{ext}"
                    save_path = os.path.join(save_dir, filename)
                    shutil.copy2(result, save_path)
                    save_status = f" / ä¿å­˜: {save_path}"
                except Exception as save_error:
                    save_status = f" / ä¿å­˜å¤±æ•—: {save_error}"
            yield state, gr.update(value=result), f"å‹•ç”»ç”Ÿæˆå®Œäº†ï¼ˆ{elapsed:.0f}ç§’ï¼‰{save_status}"
        else:
            yield state, gr.update(), f"å®Œäº†ï¼ˆå‹•ç”»ã§ã¯ãªãç”»åƒã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã¾ã—ãŸï¼‰ï¼ˆ{elapsed:.0f}ç§’ï¼‰"
    else:
        yield state, gr.update(), f"å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"


def on_save_text(
    state: dict,
    save_folder: str,
    positive: str,
    extra_instruction: str,
    video_prompt_text: str,
) -> str:
    """
    ã€Œãƒ†ã‚­ã‚¹ãƒˆä¿å­˜ã€ãƒœã‚¿ãƒ³ï¼šç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»è¿½åŠ æŒ‡ç¤ºãƒ»å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«åã¯ç¾åœ¨ã®ç”»åƒã¨åŒã˜ stem ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    """
    stem = state.get("current_image_stem", "")
    if not stem:
        stem = time.strftime("prompt_%Y%m%d_%H%M%S")

    folder = save_folder.strip() if save_folder.strip() else "."
    try:
        os.makedirs(folder, exist_ok=True)
    except Exception as e:
        return f"ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    filepath = os.path.join(folder, stem + ".txt")
    lines = []
    lines.append("=== Positive Prompt ===")
    lines.append(positive)
    lines.append("")
    lines.append("=== è¿½åŠ æŒ‡ç¤º ===")
    lines.append(extra_instruction)
    lines.append("")
    lines.append("=== å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ===")
    lines.append(video_prompt_text)

    try:
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        return f"ä¿å­˜ã—ã¾ã—ãŸ: {filepath}"
    except Exception as e:
        return f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"


# ---------------------------------------------------------------------------
# Gradio UI å®šç¾©
# ---------------------------------------------------------------------------

def build_ui():
    # Forge æœªèµ·å‹•æ™‚ã§ã‚‚ UI èµ·å‹•ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ãŸã‚ã€èµ·å‹•æ™‚ãƒã‚§ãƒƒã‚¯ã¯è¡Œã‚ãªã„
    # æ¥ç¶šç¢ºèªã¯å®Ÿéš›ã« Forge ã‚’ä½¿ã†æ“ä½œæ™‚ã«è¡Œã†
    a1111_msg = "æœªç¢ºèªï¼ˆèµ·å‹•æ™‚ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰"
    sampler_list = a1111_client.get_samplers()

    # ä¿å­˜æ¸ˆã¿è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰
    cfg_saved = settings_manager.load()
    saved_model = cfg_saved.get("model", list(qwen_client.MODEL_PRESETS.keys())[0])
    saved_positive = cfg_saved.get("positive_prompt", "")
    saved_negative = cfg_saved.get("negative_prompt", "")
    saved_steps = cfg_saved.get("steps", 28)
    saved_cfg = cfg_saved.get("cfg", 7.0)
    saved_sampler = cfg_saved.get("sampler", DEFAULT_SAMPLER)
    saved_width = cfg_saved.get("width", 512)
    saved_height = cfg_saved.get("height", 768)
    saved_seed = cfg_saved.get("seed", -1)
    saved_backend = cfg_saved.get("backend", "WebUI Forge")
    if saved_backend == "Forge 2":  # æ—§åç§°ã®ç§»è¡Œ
        saved_backend = "WebUI Forge"
    saved_comfyui_workflow = cfg_saved.get("comfyui_workflow", "")
    saved_comfyui_url = cfg_saved.get("comfyui_url", "http://127.0.0.1:8188")
    saved_comfyui_seed = cfg_saved.get("comfyui_seed", -1)
    saved_comfyui_width = cfg_saved.get("comfyui_width", 1024)
    saved_comfyui_height = cfg_saved.get("comfyui_height", 1024)
    saved_generate_count = cfg_saved.get("generate_count", 1)
    saved_save_generated_image = cfg_saved.get("save_generated_image", False)
    saved_image_save_path = cfg_saved.get("image_save_path", "./outputs/images")
    saved_save_generated_video = cfg_saved.get("save_generated_video", False)
    saved_video_save_path = cfg_saved.get("video_save_path", "./outputs/videos")
    saved_video_sections = cfg_saved.get("video_sections", ["scene", "action", "camera", "style", "prompt"])
    saved_video_width    = cfg_saved.get("video_width", None)
    saved_video_height   = cfg_saved.get("video_height", None)
    saved_video_seed     = cfg_saved.get("video_seed", -1)

    # ComfyUI URL ã‚’ comfyui_client ã«åæ˜ ãƒ»æ¥ç¶šç¢ºèª
    comfyui_client.COMFYUI_URL = saved_comfyui_url
    comfyui_client.reload_workflows()
    workflow_list = list(comfyui_client.IMAGE_WORKFLOW_PRESETS.keys())
    video_workflow_list = list(comfyui_client.VIDEO_WORKFLOW_PRESETS.keys())
    comfyui_sampler_list = comfyui_client.get_samplers()
    _, comfyui_msg = comfyui_client.check_connection()

    # ä¿å­˜ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ©ãƒ¼ãŒä¸€è¦§ã«ãªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if saved_sampler not in sampler_list:
        saved_sampler = sampler_list[0] if sampler_list else DEFAULT_SAMPLER

    initial_state = {
        "conversation_history": [],
        "current_image": None,
        "current_image_stem": "",
        "positive_prompt": saved_positive,
        "negative_prompt": saved_negative,
    }

    with gr.Blocks(title="Prompt Assistant", css=".fullscreen-button { display: none !important; }") as demo:
        state = gr.State(value=initial_state)
        sampler_choices = gr.State(value=sampler_list)

        gr.Markdown("# Prompt Assistant")

        # ---- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ï¼ˆã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆï¼‰----
        with gr.Tabs():

            # ã‚¿ãƒ–1: ç”»åƒç”Ÿæˆ
            with gr.Tab("ç”»åƒç”Ÿæˆ"):
                with gr.Row(equal_height=False):

                    # å·¦: ç”»åƒè¡¨ç¤ºã‚¨ãƒªã‚¢ï¼ˆãƒ‰ãƒ­ãƒƒãƒ—å¯¾å¿œï¼‰
                    with gr.Column(scale=1):
                        image_display = gr.Image(
                            label="ç”Ÿæˆç”»åƒ / ç”»åƒã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãƒ­ãƒ¼ãƒ‰",
                            type="pil",
                            interactive=True,
                            height=480,
                            sources=["upload", "clipboard"],
                        )
                        image_status = gr.Textbox(
                            label="ç”»åƒãƒ­ãƒ¼ãƒ‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                            interactive=False,
                            visible=True,
                            max_lines=2,
                        )

                    # ä¸­: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ï¼‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ï¼‹ ç”Ÿæˆãƒœã‚¿ãƒ³
                    with gr.Column(scale=1):
                        positive_prompt = gr.Textbox(
                            label="Positive Prompt",
                            value=saved_positive,
                            lines=6,
                            placeholder="ä¾‹: 1girl, sunset, orange sky, dramatic lighting, ...",
                        )
                        negative_prompt = gr.Textbox(
                            label="Negative Prompt",
                            value=saved_negative,
                            lines=3,
                            placeholder="ä¾‹: bad quality, worst quality, ...",
                        )

                        with gr.Row():
                            generate_btn = gr.Button("ç”»åƒç”Ÿæˆ", variant="primary", scale=3)
                            stop_btn = gr.Button("åœæ­¢", variant="secondary", scale=1)
                        count_input = gr.Number(
                            value=saved_generate_count,
                            label="ç”Ÿæˆæšæ•°",
                            precision=0,
                            minimum=1,
                        )
                        save_generated_image_checkbox = gr.Checkbox(
                            value=saved_save_generated_image,
                            label="ç”»åƒã‚’ä¿å­˜ã™ã‚‹",
                        )
                        image_save_path_input = gr.Textbox(
                            value=saved_image_save_path,
                            label="ä¿å­˜å…ˆãƒ‘ã‚¹",
                            placeholder="ä¾‹: ./outputs/images",
                            interactive=bool(saved_save_generated_image),
                        )

                        with gr.Accordion("ç”»åƒç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", open=False):
                            with gr.Row():
                                backend_radio = gr.Radio(
                                    choices=["WebUI Forge", "ComfyUI"],
                                    value=saved_backend,
                                    label="ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰",
                                )
                            _initial_conn_msg = (
                                f"ComfyUI: {comfyui_msg}" if saved_backend == "ComfyUI"
                                else f"WebUI Forge: {a1111_msg}"
                            )
                            connection_status = gr.Markdown(_initial_conn_msg)
                            comfyui_workflow_dropdown = gr.Dropdown(
                                choices=workflow_list,
                                value=saved_comfyui_workflow if saved_comfyui_workflow in workflow_list else (workflow_list[0] if workflow_list else None),
                                label="ComfyUI ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
                                visible=(saved_backend == "ComfyUI"),
                            )
                            with gr.Row():
                                steps_slider = gr.Slider(
                                    minimum=1, maximum=150, value=saved_steps, step=1, label="Steps",
                                    visible=(saved_backend != "ComfyUI"),
                                )
                                cfg_slider = gr.Slider(
                                    minimum=1.0, maximum=30.0, value=saved_cfg, step=0.5, label="CFG Scale",
                                    visible=(saved_backend != "ComfyUI"),
                                )
                            sampler_dropdown = gr.Dropdown(
                                choices=sampler_list,
                                value=saved_sampler,
                                label="Sampler",
                                visible=(saved_backend != "ComfyUI"),
                            )
                            width_input = gr.Slider(
                                minimum=64, maximum=2048, value=saved_width, step=8, label="Width",
                                visible=(saved_backend != "ComfyUI"),
                            )
                            height_input = gr.Slider(
                                minimum=64, maximum=2048, value=saved_height, step=8, label="Height",
                                visible=(saved_backend != "ComfyUI"),
                            )
                            with gr.Row():
                                seed_input = gr.Number(
                                    value=saved_seed, label="Seedï¼ˆ-1 ã§ãƒ©ãƒ³ãƒ€ãƒ ï¼‰", precision=0,
                                    visible=(saved_backend != "ComfyUI"),
                                    scale=8,
                                )
                                seed_random_btn = gr.Button("ğŸ²", size="sm", visible=(saved_backend != "ComfyUI"), scale=1, min_width=48)
                                seed_from_image_btn = gr.Button("â™»ï¸", size="sm", visible=(saved_backend != "ComfyUI"), scale=1, min_width=48)
                            with gr.Row():
                                comfyui_width_input = gr.Slider(
                                    minimum=64, maximum=2048, value=saved_comfyui_width, step=8, label="Width",
                                    visible=(saved_backend == "ComfyUI"),
                                )
                                comfyui_height_input = gr.Slider(
                                    minimum=64, maximum=2048, value=saved_comfyui_height, step=8, label="Height",
                                    visible=(saved_backend == "ComfyUI"),
                                )
                            with gr.Row():
                                comfyui_seed_input = gr.Number(
                                    value=saved_comfyui_seed, label="Seedï¼ˆ-1 ã§ãƒ©ãƒ³ãƒ€ãƒ ï¼‰", precision=0,
                                    visible=(saved_backend == "ComfyUI"),
                                    scale=8,
                                )
                                comfyui_seed_random_btn = gr.Button("ğŸ²", size="sm", visible=(saved_backend == "ComfyUI"), scale=1, min_width=48)
                                comfyui_seed_from_image_btn = gr.Button("â™»ï¸", size="sm", visible=(saved_backend == "ComfyUI"), scale=1, min_width=48)

                    # å³: Qwen3-VL ä¼šè©±ã‚¨ãƒªã‚¢
                    with gr.Column(scale=1):
                        chatbot = gr.Chatbot(
                            label="ä¼šè©± (Qwen3-VL)",
                            height=480,
                        )
                        user_input = gr.Textbox(
                            placeholder="Qwen3-VL ã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...",
                            label="",
                            lines=1,
                        )
                        with gr.Row():
                            send_btn = gr.Button("é€ä¿¡", scale=1, variant="primary")
                            clear_btn = gr.Button("ã‚¯ãƒªã‚¢", scale=1, variant="secondary")

                        # ---- ãƒ¢ãƒ‡ãƒ«è¨­å®š ----
                        with gr.Accordion("ãƒ¢ãƒ‡ãƒ«è¨­å®š", open=False):
                            with gr.Row():
                                model_dropdown = gr.Dropdown(
                                    choices=list(qwen_client.MODEL_PRESETS.keys()),
                                    value=saved_model if saved_model in qwen_client.MODEL_PRESETS else list(qwen_client.MODEL_PRESETS.keys())[0],
                                    label="Qwen3-VL ãƒ¢ãƒ‡ãƒ«",
                                    scale=3,
                                )
                                load_btn = gr.Button("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰", scale=1)
                            model_status = gr.Textbox(
                                value="ãƒ¢ãƒ‡ãƒ«æœªãƒ­ãƒ¼ãƒ‰",
                                label="ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                                interactive=False,
                            )

            # ã‚¿ãƒ–2: å‹•ç”»ç”Ÿæˆ
            with gr.Tab("å‹•ç”»ç”Ÿæˆ"):
                with gr.Row(equal_height=False):

                    # åˆ—1: ç”Ÿæˆå‹•ç”» + ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
                    with gr.Column(scale=1):
                        video_display = gr.Video(
                            label="ç”Ÿæˆå‹•ç”»",
                            height=480,
                        )
                        video_status = gr.Textbox(
                            label="å‹•ç”»ç”Ÿæˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                            interactive=False,
                            max_lines=2,
                        )

                    # åˆ—2: å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + ç”Ÿæˆ/åœæ­¢ãƒœã‚¿ãƒ³ + VRAM
                    with gr.Column(scale=1):
                        video_prompt = gr.Textbox(
                            label="å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                            lines=10,
                            interactive=True,
                            placeholder="ã€Œå‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã€ãƒœã‚¿ãƒ³ã§è‡ªå‹•ç”Ÿæˆã€ã¾ãŸã¯ç›´æ¥å…¥åŠ›",
                        )
                        with gr.Row():
                            generate_video_btn = gr.Button("å‹•ç”»ç”Ÿæˆ", variant="primary", scale=3)
                            video_stop_btn = gr.Button("åœæ­¢", variant="secondary", scale=1)

                        with gr.Accordion("VRAM", open=False):
                            free_vram_status = gr.Textbox(
                                label="VRAMè§£æ”¾ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False, lines=2,
                            )
                            with gr.Row():
                                free_qwen_btn  = gr.Button("LLM è§£æ”¾",          variant="secondary", scale=1)
                                free_forge_btn = gr.Button("WebUI Forge è§£æ”¾", variant="secondary", scale=1)
                                free_comfy_btn = gr.Button("ComfyUI è§£æ”¾",     variant="secondary", scale=1)

                        with gr.Accordion("å‹•ç”»ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", open=False):
                            video_workflow_dropdown = gr.Dropdown(
                                choices=video_workflow_list,
                                value=video_workflow_list[0] if video_workflow_list else None,
                                label="å‹•ç”»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
                            )
                            video_width_input = gr.Slider(
                                minimum=240, maximum=1920, step=16,
                                value=saved_video_width if saved_video_width else 848,
                                label="Width",
                            )
                            video_height_input = gr.Slider(
                                minimum=240, maximum=1920, step=16,
                                value=saved_video_height if saved_video_height else 480,
                                label="Height",
                            )
                            with gr.Row():
                                video_res_640_btn  = gr.Button("640 Ã— 480",  variant="secondary", size="sm")
                                video_res_1280_btn = gr.Button("1280 Ã— 720", variant="secondary", size="sm")
                            video_seed_input = gr.Number(
                                value=saved_video_seed,
                                label="Seedï¼ˆ-1 ã§ãƒ©ãƒ³ãƒ€ãƒ ï¼‰",
                                precision=0,
                            )
                            save_generated_video_checkbox = gr.Checkbox(
                                value=saved_save_generated_video,
                                label="å‹•ç”»ã‚’ä¿å­˜ã™ã‚‹",
                            )
                            video_save_path_input = gr.Textbox(
                                value=saved_video_save_path,
                                label="ä¿å­˜å…ˆURL",
                                placeholder="ä¾‹: ./outputs/videos",
                                interactive=bool(saved_save_generated_video),
                            )

                    # åˆ—3: è¿½åŠ æŒ‡ç¤º + ã‚»ã‚¯ã‚·ãƒ§ãƒ³é¸æŠ + ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                    with gr.Column(scale=1):
                        video_extra_instruction = gr.Textbox(
                            label="è¿½åŠ æŒ‡ç¤º",
                            lines=3,
                            placeholder="ä¾‹: slowly zoom in, hair flowing in the wind, cinematic lighting",
                        )
                        video_section_checkboxes = gr.CheckboxGroup(
                            choices=["scene", "action", "camera", "style", "prompt"],
                            value=saved_video_sections,
                            label="ç”Ÿæˆã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³",
                        )
                        generate_video_prompt_btn = gr.Button("å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ", variant="primary")

                        with gr.Accordion("ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜", open=False):
                            save_folder_input = gr.Textbox(
                                label="ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€",
                                value="./outputs/text",
                                placeholder="ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›...",
                            )
                            save_text_btn = gr.Button("ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜", variant="secondary")
                            save_text_status = gr.Textbox(
                                label="ä¿å­˜ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                                interactive=False,
                                max_lines=2,
                            )

        # ---- è¨­å®šè‡ªå‹•ä¿å­˜ ----

        _save_inputs = [
            model_dropdown,
            positive_prompt, negative_prompt,
            steps_slider, cfg_slider, sampler_dropdown,
            width_input, height_input, seed_input,
            backend_radio, comfyui_workflow_dropdown,
            comfyui_width_input, comfyui_height_input, comfyui_seed_input,
            count_input,
            save_generated_image_checkbox, image_save_path_input,
            save_generated_video_checkbox, video_save_path_input,
            video_section_checkboxes,
            video_width_input, video_height_input, video_seed_input,
        ]

        def _save_settings(model, positive, negative, steps, cfg, sampler, width, height, seed, backend, comfyui_workflow, comfyui_width, comfyui_height, comfyui_seed, generate_count, save_generated_image, image_save_path, save_generated_video, video_save_path, video_sections, video_width, video_height, video_seed):
            settings_manager.save({
                "model": model,
                "positive_prompt": positive,
                "negative_prompt": negative,
                "steps": int(steps),
                "cfg": float(cfg),
                "sampler": sampler,
                "width": int(width) if width else 512,
                "height": int(height) if height else 768,
                "seed": int(seed) if seed is not None else -1,
                "backend": backend,
                "comfyui_workflow": comfyui_workflow or "",
                "comfyui_width": int(comfyui_width) if comfyui_width else 1024,
                "comfyui_height": int(comfyui_height) if comfyui_height else 1024,
                "comfyui_seed": int(comfyui_seed) if comfyui_seed is not None else -1,
                "generate_count": int(generate_count) if generate_count is not None else 1,
                "save_generated_image": bool(save_generated_image),
                "image_save_path": (image_save_path or "").strip() or "./outputs/images",
                "save_generated_video": bool(save_generated_video),
                "video_save_path": (video_save_path or "").strip() or "./outputs/videos",
                "video_sections": video_sections or [],
                "video_width": int(video_width) if video_width else None,
                "video_height": int(video_height) if video_height else None,
                "video_seed": int(video_seed) if video_seed is not None else -1,
            })

        def _on_backend_change(backend):
            """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ‡ã‚Šæ›¿ãˆæ™‚ã«å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚"""
            is_comfy = backend == "ComfyUI"
            if is_comfy:
                _, latest_msg = comfyui_client.check_connection()
                conn_msg = f"ComfyUI: {latest_msg}"
            else:
                _, latest_msg = a1111_client.check_connection()
                conn_msg = f"WebUI Forge: {latest_msg}"
            return (
                gr.update(visible=is_comfy),        # comfyui_workflow_dropdown
                gr.update(visible=not is_comfy),    # steps_slider
                gr.update(visible=not is_comfy),    # cfg_slider
                gr.update(visible=not is_comfy),    # sampler_dropdown
                gr.update(visible=not is_comfy),    # width_input
                gr.update(visible=not is_comfy),    # height_input
                gr.update(visible=not is_comfy),    # seed_input
                gr.update(visible=not is_comfy),    # seed_random_btn
                gr.update(visible=not is_comfy),    # seed_from_image_btn
                gr.update(visible=is_comfy),        # comfyui_width_input
                gr.update(visible=is_comfy),        # comfyui_height_input
                gr.update(visible=is_comfy),        # comfyui_seed_input
                gr.update(visible=is_comfy),        # comfyui_seed_random_btn
                gr.update(visible=is_comfy),        # comfyui_seed_from_image_btn
                gr.update(value=conn_msg),          # connection_status
            )

        def _on_save_image_toggle(enabled):
            return gr.update(interactive=bool(enabled))

        def _on_save_video_toggle(enabled):
            return gr.update(interactive=bool(enabled))

        for _comp in _save_inputs:
            _comp.change(fn=_save_settings, inputs=_save_inputs, outputs=[])

        backend_radio.change(
            fn=_on_backend_change,
            inputs=[backend_radio],
            outputs=[
                comfyui_workflow_dropdown,
                steps_slider, cfg_slider, sampler_dropdown,
                width_input, height_input, seed_input,
                seed_random_btn, seed_from_image_btn,
                comfyui_width_input, comfyui_height_input, comfyui_seed_input,
                comfyui_seed_random_btn, comfyui_seed_from_image_btn,
                connection_status,
            ],
        )
        save_generated_image_checkbox.change(
            fn=_on_save_image_toggle,
            inputs=[save_generated_image_checkbox],
            outputs=[image_save_path_input],
        )
        save_generated_video_checkbox.change(
            fn=_on_save_video_toggle,
            inputs=[save_generated_video_checkbox],
            outputs=[video_save_path_input],
        )

        # ---- ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š ----

        seed_random_btn.click(fn=on_set_seed_random, inputs=[], outputs=[seed_input])
        comfyui_seed_random_btn.click(fn=on_set_seed_random, inputs=[], outputs=[comfyui_seed_input])
        seed_from_image_btn.click(
            fn=on_set_seed_from_current_image,
            inputs=[state],
            outputs=[seed_input, image_status],
        )
        comfyui_seed_from_image_btn.click(
            fn=on_set_seed_from_current_image,
            inputs=[state],
            outputs=[comfyui_seed_input, image_status],
        )

        load_btn.click(
            fn=on_load_model,
            inputs=[model_dropdown],
            outputs=[model_status],
        )

        image_display.upload(
            fn=on_image_drop,
            inputs=[image_display, state, sampler_choices],
            outputs=[
                state,
                positive_prompt, negative_prompt,
                steps_slider, cfg_slider, sampler_dropdown,
                width_input, height_input, seed_input, comfyui_seed_input,
                image_status,
            ],
        )

        clear_btn.click(
            fn=on_clear,
            inputs=[state],
            outputs=[state, chatbot],
        )

        send_btn.click(
            fn=on_send,
            inputs=[user_input, state, chatbot, model_dropdown, positive_prompt, negative_prompt],
            outputs=[state, chatbot, positive_prompt, negative_prompt, user_input, model_status],
        )

        user_input.submit(
            fn=on_send,
            inputs=[user_input, state, chatbot, model_dropdown, positive_prompt, negative_prompt],
            outputs=[state, chatbot, positive_prompt, negative_prompt, user_input, model_status],
        )

        gen_event = generate_btn.click(
            fn=on_generate,
            inputs=[
                state,
                positive_prompt, negative_prompt,
                steps_slider, cfg_slider, sampler_dropdown,
                width_input, height_input, seed_input,
                backend_radio, comfyui_workflow_dropdown,
                comfyui_width_input, comfyui_height_input, comfyui_seed_input,
                count_input,
                save_generated_image_checkbox, image_save_path_input,
            ],
            outputs=[state, image_display, image_status],
        )

        stop_btn.click(fn=None, cancels=[gen_event])

        free_qwen_btn.click(fn=on_free_qwen,    inputs=[], outputs=[free_vram_status])
        free_forge_btn.click(fn=on_free_forge,  inputs=[], outputs=[free_vram_status])
        free_comfy_btn.click(fn=on_free_comfyui, inputs=[], outputs=[free_vram_status])

        # ---- å‹•ç”»ç”Ÿæˆã‚¤ãƒ™ãƒ³ãƒˆ ----

        video_res_640_btn.click(
            fn=lambda: (640, 480),
            inputs=[],
            outputs=[video_width_input, video_height_input],
        )
        video_res_1280_btn.click(
            fn=lambda: (1280, 720),
            inputs=[],
            outputs=[video_width_input, video_height_input],
        )

        gen_video_prompt_event = generate_video_prompt_btn.click(
            fn=on_generate_video_prompt,
            inputs=[state, positive_prompt, video_extra_instruction, video_section_checkboxes],
            outputs=[video_prompt],
        )

        gen_video_event = generate_video_btn.click(
            fn=on_generate_video,
            inputs=[state, video_prompt, video_workflow_dropdown, video_seed_input, video_width_input, video_height_input, save_generated_video_checkbox, video_save_path_input],
            outputs=[state, video_display, video_status],
        )

        video_stop_btn.click(
            fn=on_stop_video,
            inputs=[],
            outputs=[video_status],
            cancels=[gen_video_prompt_event, gen_video_event],
        )

        save_text_btn.click(
            fn=on_save_text,
            inputs=[state, save_folder_input, positive_prompt, video_extra_instruction, video_prompt],
            outputs=[save_text_status],
        )

    return demo


if __name__ == "__main__":
    app = build_ui()
    app.queue()
    app.launch(inbrowser=True)
